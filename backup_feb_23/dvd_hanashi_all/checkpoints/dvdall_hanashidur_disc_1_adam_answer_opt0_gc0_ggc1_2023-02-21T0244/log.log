02/21/2023 02:44:06 0
02/21/2023 02:44:06 Launching the MT-DNN training
02/21/2023 02:44:06 Loading ../../../dvd_hanashi/dvd_hanashi_all/1/dvdppf_train.json as task 0
02/21/2023 02:44:06 Loading ../../../dvd_hanashi/dvd_hanashi_all/1/dvdduration_train.json as task 1
02/21/2023 02:44:06 Loading ../../../dvd_hanashi/dvd_hanashi_all/1/dvdorder_train.json as task 2
02/21/2023 02:44:06 Loading ../../../dvd_hanashi/dvd_hanashi_all/1/hanashiduration_train.json as task 3
02/21/2023 02:44:06 Loading ../../../dvd_hanashi/dvd_hanashi_all/1/disc_train.json as task 4
02/21/2023 02:44:06 4,5,6,8,2
02/21/2023 02:44:06 ####################
02/21/2023 02:44:06 {'log_file': 'checkpoints/dvdall_hanashidur_disc_1_adam_answer_opt0_gc0_ggc1_2023-02-21T0244/log.log', 'tensorboard': False, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': '../../../japanese_bert_new_/jap_bert.pt', 'data_dir': '../../../dvd_hanashi/dvd_hanashi_all/1/', 'data_sort_on': False, 'name': 'farmer', 'task_def': '../../../experiments/dvd_hanashi/dvd_hanashi_task_def.yml', 'train_datasets': ['dvdppf', 'dvdduration', 'dvdorder', 'hanashiduration', 'disc'], 'test_datasets': ['dvdppf', 'dvdduration', 'dvdorder', 'hanashiduration', 'disc'], 'update_bert_opt': 0, 'multi_gpu_on': True, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': [0, 0, 0, 0, 0], 'label_size': '4,5,6,8,2', 'mtl_opt': 0, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': <EncoderModelType.BERT: 1>, 'cuda': True, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 10, 'batch_size': 16, 'batch_size_eval': 8, 'optimizer': 'adam', 'grad_clipping': 0.0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 1e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-06, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'ema_opt': 0, 'ema_gamma': 0.995, 'lookahead': False, 'lookahead_k': 5, 'lookahead_alpha': 0.5, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'freeze_layers': -1, 'embedding_opt': 0, 'lr_gamma': 0.5, 'bert_l2norm': 0.0, 'scheduler_type': 'ms', 'output_dir': 'checkpoints/dvdall_hanashidur_disc_1_adam_answer_opt0_gc0_ggc1_2023-02-21T0244', 'seed': 2018, 'grad_accumulation_step': 1, 'fp16': False, 'fp16_opt_level': 'O1', 'mean_teacher': False, 'mean_teacher_avg': 'exponential', 'mean_teacher_lambda': 1, 'mean_teacher_rampup': 4000, 'mean_teacher_alpha1': 0.99, 'mean_teacher_alpha2': 0.999, 'mt_kd_tau': 1, 'virtual_teacher': False, 'vat_eps': 0.001, 'vat_max_layer': -1, 'vat_opt': 0, 'vat_lambda': 1, 'vat_alpha': 1, 'vat_nosiy': 1e-05, 'use_noisycopy': False, 'noisycopy_eps': 0.01, 'use_advcopy': False, 'advcopy_eps': 0.01, 'vat_stable_eps': 1e-06, 'tasks_dropout_p': [0.1, 0.1, 0.1, 0.1, 0.1]}
02/21/2023 02:44:06 ####################
02/21/2023 02:44:06 ############# Gradient Accumulation Info #############
02/21/2023 02:44:06 number of step: 8320
02/21/2023 02:44:06 number of grad grad_accumulation step: 1
02/21/2023 02:44:06 adjusted number of step: 8320
02/21/2023 02:44:06 ############# Gradient Accumulation Info #############
02/21/2023 02:44:14 
############# Model Arch of MT-DNN #############
SANBertNetwork(
  (dropout_list): ModuleList(
    (0): DropoutWrapper()
    (1): DropoutWrapper()
    (2): DropoutWrapper()
    (3): DropoutWrapper()
    (4): DropoutWrapper()
  )
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(32006, 768)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (scoring_list): ModuleList(
    (0): Linear(in_features=768, out_features=4, bias=True)
    (1): Linear(in_features=768, out_features=5, bias=True)
    (2): Linear(in_features=768, out_features=6, bias=True)
    (3): Linear(in_features=768, out_features=8, bias=True)
    (4): Linear(in_features=768, out_features=2, bias=True)
  )
)

02/21/2023 02:44:14 Total number of params: 110641177
02/21/2023 02:44:14 At epoch 0
02/21/2023 02:44:18 Task [ 4] updates[     1] train loss[0.70879] remaining[1:04:56]
02/21/2023 02:46:16 Task [ 4] updates[   500] train loss[1.09257] remaining[0:01:21]
02/21/2023 02:47:36 Task dvdppf -- epoch 0 -- Dev ACC: 45.643
02/21/2023 02:47:36 Task dvdppf -- epoch 0 -- Dev F1: 26.568
02/21/2023 02:47:37 Task dvdduration -- epoch 0 -- Dev ACC: 44.813
02/21/2023 02:47:37 Task dvdduration -- epoch 0 -- Dev F1: 12.378
02/21/2023 02:47:39 Task dvdorder -- epoch 0 -- Dev ACC: 41.117
02/21/2023 02:47:39 Task dvdorder -- epoch 0 -- Dev F1: 9.712
02/21/2023 02:47:44 Task hanashiduration -- epoch 0 -- Dev ACC: 34.681
02/21/2023 02:47:44 Task hanashiduration -- epoch 0 -- Dev F1: 6.500
02/21/2023 02:47:51 Task disc -- epoch 0 -- Dev ACC: 97.824
02/21/2023 02:47:51 Task disc -- epoch 0 -- Dev F1: 96.829
02/21/2023 02:47:51 At epoch 1
02/21/2023 02:48:30 Task [ 4] updates[  1000] train loss[1.04422] remaining[0:02:33]
02/21/2023 02:50:28 Task [ 4] updates[  1500] train loss[1.01401] remaining[0:00:38]
02/21/2023 02:51:08 Task dvdppf -- epoch 1 -- Dev ACC: 53.527
02/21/2023 02:51:08 Task dvdppf -- epoch 1 -- Dev F1: 37.659
02/21/2023 02:51:10 Task dvdduration -- epoch 1 -- Dev ACC: 50.622
02/21/2023 02:51:10 Task dvdduration -- epoch 1 -- Dev F1: 23.213
02/21/2023 02:51:11 Task dvdorder -- epoch 1 -- Dev ACC: 40.609
02/21/2023 02:51:11 Task dvdorder -- epoch 1 -- Dev F1: 9.662
02/21/2023 02:51:16 Task hanashiduration -- epoch 1 -- Dev ACC: 41.422
02/21/2023 02:51:16 Task hanashiduration -- epoch 1 -- Dev F1: 11.439
02/21/2023 02:51:23 Task disc -- epoch 1 -- Dev ACC: 96.973
02/21/2023 02:51:23 Task disc -- epoch 1 -- Dev F1: 95.636
02/21/2023 02:51:23 At epoch 2
02/21/2023 02:52:42 Task [ 0] updates[  2000] train loss[0.99100] remaining[0:01:56]
02/21/2023 02:54:40 Task dvdppf -- epoch 2 -- Dev ACC: 49.793
02/21/2023 02:54:40 Task dvdppf -- epoch 2 -- Dev F1: 35.047
02/21/2023 02:54:42 Task dvdduration -- epoch 2 -- Dev ACC: 48.963
02/21/2023 02:54:42 Task dvdduration -- epoch 2 -- Dev F1: 28.971
02/21/2023 02:54:43 Task dvdorder -- epoch 2 -- Dev ACC: 43.147
02/21/2023 02:54:43 Task dvdorder -- epoch 2 -- Dev F1: 17.925
02/21/2023 02:54:48 Task hanashiduration -- epoch 2 -- Dev ACC: 42.034
02/21/2023 02:54:48 Task hanashiduration -- epoch 2 -- Dev F1: 16.521
02/21/2023 02:54:55 Task disc -- epoch 2 -- Dev ACC: 97.067
02/21/2023 02:54:55 Task disc -- epoch 2 -- Dev F1: 95.804
02/21/2023 02:54:55 At epoch 3
02/21/2023 02:54:56 Task [ 0] updates[  2500] train loss[0.96333] remaining[0:03:00]
02/21/2023 02:56:54 Task [ 4] updates[  3000] train loss[0.93397] remaining[0:01:17]
02/21/2023 02:58:12 Task dvdppf -- epoch 3 -- Dev ACC: 51.867
02/21/2023 02:58:12 Task dvdppf -- epoch 3 -- Dev F1: 38.066
02/21/2023 02:58:15 Task dvdduration -- epoch 3 -- Dev ACC: 48.548
02/21/2023 02:58:15 Task dvdduration -- epoch 3 -- Dev F1: 30.202
02/21/2023 02:58:16 Task dvdorder -- epoch 3 -- Dev ACC: 40.102
02/21/2023 02:58:16 Task dvdorder -- epoch 3 -- Dev F1: 16.804
02/21/2023 02:58:22 Task hanashiduration -- epoch 3 -- Dev ACC: 41.176
02/21/2023 02:58:22 Task hanashiduration -- epoch 3 -- Dev F1: 18.472
02/21/2023 02:58:28 Task disc -- epoch 3 -- Dev ACC: 96.878
02/21/2023 02:58:28 Task disc -- epoch 3 -- Dev F1: 95.506
02/21/2023 02:58:28 At epoch 4
02/21/2023 02:59:09 Task [ 1] updates[  3500] train loss[0.90889] remaining[0:02:34]
02/21/2023 03:01:05 Task [ 2] updates[  4000] train loss[0.88306] remaining[0:00:37]
02/21/2023 03:01:44 Task dvdppf -- epoch 4 -- Dev ACC: 51.452
02/21/2023 03:01:44 Task dvdppf -- epoch 4 -- Dev F1: 37.018
02/21/2023 03:01:46 Task dvdduration -- epoch 4 -- Dev ACC: 45.643
02/21/2023 03:01:46 Task dvdduration -- epoch 4 -- Dev F1: 30.493
02/21/2023 03:01:47 Task dvdorder -- epoch 4 -- Dev ACC: 39.594
02/21/2023 03:01:47 Task dvdorder -- epoch 4 -- Dev F1: 18.398
02/21/2023 03:01:53 Task hanashiduration -- epoch 4 -- Dev ACC: 39.951
02/21/2023 03:01:53 Task hanashiduration -- epoch 4 -- Dev F1: 18.640
02/21/2023 03:01:59 Task disc -- epoch 4 -- Dev ACC: 97.162
02/21/2023 03:01:59 Task disc -- epoch 4 -- Dev F1: 95.945
02/21/2023 03:01:59 At epoch 5
02/21/2023 03:03:20 Task [ 3] updates[  4500] train loss[0.85625] remaining[0:01:56]
02/21/2023 03:05:17 Task dvdppf -- epoch 5 -- Dev ACC: 47.303
02/21/2023 03:05:17 Task dvdppf -- epoch 5 -- Dev F1: 35.770
02/21/2023 03:05:18 Task dvdduration -- epoch 5 -- Dev ACC: 46.888
02/21/2023 03:05:18 Task dvdduration -- epoch 5 -- Dev F1: 30.684
02/21/2023 03:05:20 Task dvdorder -- epoch 5 -- Dev ACC: 42.132
02/21/2023 03:05:20 Task dvdorder -- epoch 5 -- Dev F1: 22.102
02/21/2023 03:05:25 Task hanashiduration -- epoch 5 -- Dev ACC: 40.074
02/21/2023 03:05:25 Task hanashiduration -- epoch 5 -- Dev F1: 18.324
02/21/2023 03:05:32 Task disc -- epoch 5 -- Dev ACC: 96.783
02/21/2023 03:05:32 Task disc -- epoch 5 -- Dev F1: 95.404
02/21/2023 03:05:32 At epoch 6
02/21/2023 03:05:34 Task [ 3] updates[  5000] train loss[0.83490] remaining[0:03:17]
02/21/2023 03:07:31 Task [ 4] updates[  5500] train loss[0.81314] remaining[0:01:15]
02/21/2023 03:08:50 Task dvdppf -- epoch 6 -- Dev ACC: 46.473
02/21/2023 03:08:50 Task dvdppf -- epoch 6 -- Dev F1: 34.992
02/21/2023 03:08:51 Task dvdduration -- epoch 6 -- Dev ACC: 42.324
02/21/2023 03:08:51 Task dvdduration -- epoch 6 -- Dev F1: 29.583
02/21/2023 03:08:53 Task dvdorder -- epoch 6 -- Dev ACC: 39.594
02/21/2023 03:08:53 Task dvdorder -- epoch 6 -- Dev F1: 23.677
02/21/2023 03:08:58 Task hanashiduration -- epoch 6 -- Dev ACC: 37.623
02/21/2023 03:08:58 Task hanashiduration -- epoch 6 -- Dev F1: 15.902
02/21/2023 03:09:05 Task disc -- epoch 6 -- Dev ACC: 96.973
02/21/2023 03:09:05 Task disc -- epoch 6 -- Dev F1: 95.687
02/21/2023 03:09:05 At epoch 7
02/21/2023 03:09:45 Task [ 1] updates[  6000] train loss[0.79060] remaining[0:02:31]
02/21/2023 03:11:42 Task [ 2] updates[  6500] train loss[0.76947] remaining[0:00:36]
02/21/2023 03:12:21 Task dvdppf -- epoch 7 -- Dev ACC: 50.207
02/21/2023 03:12:21 Task dvdppf -- epoch 7 -- Dev F1: 36.937
02/21/2023 03:12:22 Task dvdduration -- epoch 7 -- Dev ACC: 40.664
02/21/2023 03:12:22 Task dvdduration -- epoch 7 -- Dev F1: 29.681
02/21/2023 03:12:24 Task dvdorder -- epoch 7 -- Dev ACC: 42.640
02/21/2023 03:12:24 Task dvdorder -- epoch 7 -- Dev F1: 24.146
02/21/2023 03:12:29 Task hanashiduration -- epoch 7 -- Dev ACC: 35.294
02/21/2023 03:12:29 Task hanashiduration -- epoch 7 -- Dev F1: 16.158
02/21/2023 03:12:36 Task disc -- epoch 7 -- Dev ACC: 97.162
02/21/2023 03:12:36 Task disc -- epoch 7 -- Dev F1: 95.945
02/21/2023 03:12:36 At epoch 8
02/21/2023 03:13:57 Task [ 4] updates[  7000] train loss[0.74997] remaining[0:01:54]
02/21/2023 03:15:53 Task dvdppf -- epoch 8 -- Dev ACC: 47.303
02/21/2023 03:15:53 Task dvdppf -- epoch 8 -- Dev F1: 35.285
02/21/2023 03:15:54 Task dvdduration -- epoch 8 -- Dev ACC: 42.739
02/21/2023 03:15:54 Task dvdduration -- epoch 8 -- Dev F1: 30.032
02/21/2023 03:15:56 Task dvdorder -- epoch 8 -- Dev ACC: 38.579
02/21/2023 03:15:56 Task dvdorder -- epoch 8 -- Dev F1: 24.321
02/21/2023 03:16:01 Task hanashiduration -- epoch 8 -- Dev ACC: 34.314
02/21/2023 03:16:01 Task hanashiduration -- epoch 8 -- Dev F1: 15.980
02/21/2023 03:16:08 Task disc -- epoch 8 -- Dev ACC: 97.256
02/21/2023 03:16:08 Task disc -- epoch 8 -- Dev F1: 96.074
02/21/2023 03:16:08 At epoch 9
02/21/2023 03:16:11 Task [ 2] updates[  7500] train loss[0.73201] remaining[0:03:18]
02/21/2023 03:18:09 Task [ 3] updates[  8000] train loss[0.71475] remaining[0:01:15]
02/21/2023 03:19:25 Task dvdppf -- epoch 9 -- Dev ACC: 47.303
02/21/2023 03:19:25 Task dvdppf -- epoch 9 -- Dev F1: 34.948
02/21/2023 03:19:27 Task dvdduration -- epoch 9 -- Dev ACC: 41.909
02/21/2023 03:19:27 Task dvdduration -- epoch 9 -- Dev F1: 30.694
02/21/2023 03:19:28 Task dvdorder -- epoch 9 -- Dev ACC: 37.563
02/21/2023 03:19:28 Task dvdorder -- epoch 9 -- Dev F1: 23.956
02/21/2023 03:19:33 Task hanashiduration -- epoch 9 -- Dev ACC: 35.049
02/21/2023 03:19:33 Task hanashiduration -- epoch 9 -- Dev F1: 15.911
02/21/2023 03:19:40 Task disc -- epoch 9 -- Dev ACC: 97.256
02/21/2023 03:19:40 Task disc -- epoch 9 -- Dev F1: 96.074
